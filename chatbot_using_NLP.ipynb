{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# importing important libraries\n",
        "import nltk\n",
        "import string\n",
        "import random"
      ],
      "metadata": {
        "id": "WRirJNrwCbqx"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('chat.txt', 'r', errors='ignore') # opening the document\n",
        "raw_doc = f.read() # Reading the document\n",
        "raw_doc = raw_doc.lower()  # Converts text to lowercase"
      ],
      "metadata": {
        "id": "CoJJWA7SCbvb"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading important NLTK functions\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "rKn-7jA0CbzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokens = nltk.sent_tokenize(raw_doc)  # Convert doc to a list of sentences\n",
        "word_tokens = nltk.word_tokenize(raw_doc)  # Convert doc to a list of words"
      ],
      "metadata": {
        "id": "OjfWWrUbCb1q"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmer = nltk.stem.WordNetLemmatizer() # create an instance of the WordNetLemmatizer class"
      ],
      "metadata": {
        "id": "SxdiswZNCb4h"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LemTokens(tokens):\n",
        "    \"\"\"takes a list of tokens as input and returns a list of lemmatized tokens\"\"\"\n",
        "    return [lemmer.lemmatize(token) for token in tokens]"
      ],
      "metadata": {
        "id": "B0N-yxDvCb9e"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation) #creates a dictionary using a dictionary comprehension"
      ],
      "metadata": {
        "id": "WtA-ME5cCb_0"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LemNormalize(text):\n",
        "    \"\"\"performs text normalization using lemmatization and removal of punctuation\"\"\"\n",
        "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
      ],
      "metadata": {
        "id": "c7PVyfHlCcB5"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GREET_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\", \"hey\")\n",
        "GREET_RESPONSES = [\"hi\", \"hey\", \"nods\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]"
      ],
      "metadata": {
        "id": "9VHzxgh8CcEg"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def greet(sentence):\n",
        "    \"\"\" Function for greeting sentence \"\"\"\n",
        "    for word in sentence.split():\n",
        "        if word.lower() in GREET_INPUTS:\n",
        "            return random.choice(GREET_RESPONSES)"
      ],
      "metadata": {
        "id": "9rQfzeZ1CcG2"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def response(user_response):\n",
        "    robo1_response = ''\n",
        "\n",
        "    # Check for greetings\n",
        "    greeting = greet(user_response)\n",
        "    if greeting:\n",
        "        return \"BOT: \" + greeting\n",
        "\n",
        "    found_answer = False\n",
        "\n",
        "    for idx, sentence in enumerate(sent_tokens):\n",
        "        if user_response in sentence.lower():\n",
        "            # Assuming the corresponding answer is in the next sentence\n",
        "            robo1_response = sent_tokens[idx + 1] if idx + 1 < len(sent_tokens) else \"I am sorry! I don't have an answer for that.\"\n",
        "            found_answer = True\n",
        "            break\n",
        "\n",
        "    # If no matching question is found, provide a default response\n",
        "    if not found_answer:\n",
        "        robo1_response = \"I am sorry! I don't have an answer for that.\"\n",
        "\n",
        "    return robo1_response\n",
        "\n",
        "\n",
        "flag = True\n",
        "print(\"BOT: My name is poc. Let's have a conversation. Also, if you want to exit any time, just type Bye!\")\n",
        "\n",
        "while flag:\n",
        "    user_response = input()\n",
        "    user_response = user_response.lower()\n",
        "\n",
        "    if user_response != 'bye':\n",
        "        if user_response == 'thanks' or user_response == 'thank you':\n",
        "            flag = False\n",
        "            print(\"BOT: You are welcome.\")\n",
        "        else:\n",
        "            print(response(user_response))\n",
        "    else:\n",
        "        flag = False\n",
        "        print(\"BOT: Goodbye! Take care <3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTo6cREGDVkO",
        "outputId": "2d02a182-edad-43f7-f67a-a2c744b74685"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOT: My name is poc. Let's have a conversation. Also, if you want to exit any time, just type Bye!\n",
            "hi\n",
            "BOT: I am glad! You are talking to me\n",
            "What is data science used for?\n",
            "data science is used to study data in four main ways:\n",
            "1. descriptive analysis\n",
            "descriptive analysis examines data to gain insights into what happened or what is happening in the data environment.\n",
            "bye\n",
            "BOT: Goodbye! Take care <3\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}